---
title: "DATA 624 Homework 4"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: kate
    toc_depth: 3
    code_folding: "show"
---


```{r setup, echo=FALSE, cache=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment=NA, message=FALSE, warning=FALSE)
library(tidyverse)
library(corrplot)
library(Amelia)
library(kableExtra)
library(caret)
```

## Question 3.1

The UC Irvine Machine Learning Repository contains a data set related to glass identification.  The data  consists of 214 glass samples labeled as one of several class categories.  There are nine predictors, including the refractive index and percentages of eight elements: Na, Mg, Al, Si, K, Ca, Ba, and Fe.  The data can be accessed via:

```{r}
library(mlbench)
data(Glass)
str(Glass)
```

(a) Using visualizations, explore the predictor variables to understand their distributions as well as the relationships between predictors

**Before looking at the relationships I think it would be helpful to know a bit more about the predictors.  T element concentrations predictors' unit of measurement, according to [UCI documentation](http://archive.ics.uci.edu/ml/datasets/Glass+Identification) is the "weight percent in corresponding oxide."  There is no documentation on the refractive index provided by UCI.  But according to Wikipedia, the refractive index measure how much light slows down by passing through a material.  An increasing refractive index corresponds to decreasing speed of light in the material.**

**Now that we have an inkling of what the data represent, we will take a look at the distribution of the predictors:**

```{r}
long_glass <- Glass %>%
  pivot_longer(-Type, names_to = "Predictor", values_to = "Value", values_drop_na = TRUE) %>%
  mutate(Predictor = as.factor(Predictor))

long_glass %>%
  ggplot(aes(Value, color = Predictor, fill = Predictor)) +
  geom_histogram(bins = 20) +
  facet_wrap(~ Predictor, ncol = 3, scales = "free") +
  scale_fill_brewer(palette = "Set1") +
  scale_color_brewer(palette = "Set1") +
  theme_light() +
  theme(legend.position = "none") +
  ggtitle("Distribution of Predictor Variables")
```

**Glass is primarly made of silica (Si), soda (Na) and lime (Ca).  Seeing these predictors at higher concentrations is not suprising.**

**Now we will examine how the predictors are related to eachother.  We will do that with a correlation plot.**

```{r}
#ColorBrewer's 5 class spectral color palette
col <- colorRampPalette(c("#d7191c", "#fdae61", "#ffffbf", "#abdda4", "#2b83ba"))

Glass %>%
  select(-Type) %>%
  cor() %>%
  round(., 2) %>%
  corrplot(., method="color", col=col(200), type="upper", order="hclust", addCoef.col = "black", tl.col="black", tl.srt=45, diag=FALSE )
```

**Most of the predictors are negatively correlated, which makes sense.  They are measuring chemical concentrations on a percentage basis.  As one element increases we would expect a decrease in the others.**

**Most of the correlations are not very strong.  The exception to this is the correlation between calcium oxide and the refraction index is strongly positively correlated.  I am going to take some liberties and summarize the data in a tabular form, because this "visualization" speaks to me:**

```{r, echo=FALSE}
long_glass %>%
  group_by(Predictor) %>%
  summarise(Min = min(Value),
            `1st Qu.` = quantile(Value, .25),
            Median = median(Value),
            Mean = mean(Value),
            `3rd Qu.` = quantile(Value, .75),
            Max = max(Value)) %>%
  kable() %>%
  kable_styling()
```

(b) Do there appear to be any outliers in the data?  Are any predictors skewed?

**I want to see how the predictors are distributed by the type of glass.  I will use a scatter plot to do this but will be excluding scilica because of the difference in scale.**

```{r}
long_glass %>%
  ggplot(aes(x = Type, y = Value, color = Predictor)) +
  geom_jitter() +
  ylim(0, 20) + 
  scale_color_brewer(palette = "Set1") +
  theme_light()
```

**It looks like glass type 1, 2 and 3 are very similar in chemical composition.  There are a couple of observations that appear to be outliers.  For example there are a couple of potasium (K) observations in the type 5 glass that are unusually high.  There is a barium (Ba) observation in type 2 glass that apears to be an outlier along with some calcium (Ca) observations in type 2 glass.**

**Magnesium is bimodal and left skewed. Iron, potasium and barium are right skewed.  The other predictors are somewhat normal.**

(c) Are there any relevant transformations of one or more predictors that might improve the classification model?

**Something like a Box-Cox transformation might improve the classification model's preformance.**

## Question 3.2

The soybean data can also be found at the UC Irvine Machine Learning Repository.  Data were collected to predict disease in 683 soybeans.  The 35 predictors are mostly categorical and include information on the environemental conditions (e.g. temperature, precipitation) and plant conditions (e.g., left spots, mold growth).  The outcome labels consist of 19 distinct classes.  The data can be loaded via:

```{r}
library(mlbench)
data(Soybean)
## See ?Soybean for details
```

(a) Investigate the frequency distributions for the categorical predictors.  Are any of the distributions degenerate in the ways discussed earlier in this chapter?

**I am assuming the degenerate distibuted variaviables discussed earlier in the chapter referes to section 3.5 on removing predictors.  Here's some frequency tables:**

```{r, results='asis'}
for (predictor in names(select(Soybean, -Class))){
  temp <- Soybean %>%
    group_by(.dots=predictor) %>%
    tally() %>%
    arrange(desc(n)) 
  temp %>%
    summarise(total = sum(n)) %>%
    merge(temp) %>%
    mutate(share = n / total) %>%
    select(-total) %>%
    kable() %>%
    kable_styling() %>%
    print()
}
```

**There's a lot of missing variables. The authors recommended removing variables with near zero variance.  I know that the `caret` package has a function for that.  Here's the output from that function:**

```{r}
nearZeroVar(Soybean, saveMetrics = T) %>%
  kable() %>%
  kable_styling()
```

**There are three variables (`r names(Soybean)[caret::nearZeroVar(Soybean)]`) that have a near zero variance, and should probably be removed.**

(b) Roughly 18% of the data are missing.  Are there particular predictors that are more likely to be missing?  Is the pattern of missing data related to the classes?

```{r}
Soybean %>%
  arrange(Class) %>%
  missmap(main = "Missing vs Observed")
```

**There are blocks of observations that are missing.  Since the data are arranged by the classes this suggests that the patterns of missing data are related to the classes.**

(c) Develop a strategy for handling missing data, either by eliminating predictors or imputation.

**In my training it has been encouraged to never get rid of data, so my bias would be towards filling them with imputation.**

**I would first drop all missing variables and run it through a random forest to determine which variables are important.  If the near zero variance variables are not high in the list, I would drop them since they have little informational value.**

**If one of the important variables has a lot of missing data I would use k-means to fill in the holes with this categorical data.  If the variables were quantitative I would probably use the mean or median to fill in the holes.**
