---
title: "DATA 624 Project 1 Part A - ATM"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: kate
    toc_depth: 3
    code_folding: "hide"
---


```{r setup, echo=FALSE, cache=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment=NA, message=FALSE, warning=FALSE)
library(tidyverse)
library(lubridate)
library(kableExtra)
library(readxl)
library(fpp2)
library(prophet)
library(forcats)
```

## Introduction

I am to forecast how much cash will be taken out of 4 different ATM machines for May 2010.  Data was provided for this project.  The cash is in hundreds of dollars.

## Data Exploration

I will begin by plotting the cash withdrawn by each ATM.

```{r}
atm <- read_excel("ATM624Data.xlsx") %>%
  mutate(DATE = as.Date(DATE, origin = "1899-12-30"),
         ATM = as.factor(ATM)) %>%
  data.frame()

atm %>%
  ggplot(aes(DATE, Cash, color=ATM)) +
  geom_line(lwd=1) +
  ggtitle("Cash Withdrawal by Date and ATM") +
  scale_color_brewer(palette = "Set1") + 
  theme(legend.title = element_blank(),
        legend.position = "bottom",
        axis.title = element_blank())
```

ATM #4 is utilized at a higher rate than every other ATM in the data series.  There is an unusual spike in ATM #4.  According to a [2010 article in Time magazine](https://business.time.com/2010/10/07/more-thevies-are-making-total-atm-withdrawls/) an average sized ATM can hold $200,000.  So the outlier is an implausible figure.  There are some missing ATM labels in the data.  Let's remove ATM #4 and the missing label from the dataset and replot the visualization:

```{r}
atm %>%
  filter(ATM != "ATM4") %>%
  filter(!is.na(ATM)) %>%
  ggplot(aes(DATE, Cash, color=ATM)) +
  geom_line(lwd=1) +
  ggtitle("Cash Withdrawal by Date and ATM") +
  scale_color_brewer(palette = "Set1") + 
  theme(legend.title = element_blank(),
        legend.position = "bottom",
        axis.title = element_blank())
```

It looks like ATM #3 was not utilized until recently.  ATM #1 and #2 seem very similar to each other.  It doesn't seem like there is much of a trend in the data.  Let's explore the distributions further with this visualization:

```{r}
atm %>%
  na.omit() %>%
  ggplot(aes(ATM, Cash, color = ATM)) +
  geom_boxplot() +
  ggtitle("Cash Withdrawal by ATM") +
  scale_color_brewer(palette = "Set1") +
  facet_wrap(.~ATM, nrow = 2, scales = "free") +
  theme(legend.position = "none",
        axis.title.y = element_blank(),
        axis.title.x = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank())

atm %>%
  filter(!is.na(ATM)) %>%
  group_by(ATM) %>%
  summarise(Minimum = min(Cash, na.rm = T),
            `1st Qu.` = quantile(Cash, .25, na.rm = T),
            Mean = mean(Cash, na.rm = T),
            Median = median(Cash, na.rm = T),
            `3rd Qu.` = quantile(Cash, .75, na.rm = T),
            Maximum = max(Cash, na.rm = T),
            `NA's` = sum(is.na(Cash))) %>%
  kable() %>%
  kable_styling()
```

### Dealing with Missing Data & Outliers

ATM #1 is missing 3 observations and ATM #2 is missing 2.  I will replace the NA's with the median values.  We will also replace all the outliers in ATM #4 with the $200,000. 

```{r}
adjusted_atm <- atm %>% 
  rowwise() %>%
  mutate(Cash = if_else(is.na(Cash) & ATM == "ATM1", 91, Cash)) %>%
  mutate(Cash = if_else(is.na(Cash) & ATM == "ATM2", 67, Cash)) %>%
  mutate(Cash = if_else(Cash > 2000, 2000, Cash)) %>%
  ungroup() %>%
  data.frame()
```

## Model Building

I will construct a series of models using different approaches. I will start from the most simple approach and move on to more sophisticated ones.  I beleive the "best" model will come from the middle of the pack.  Let's see how it plays out.

Since the task is to predict the cash withdrawls for May 2010 (31 days) we will set up test sets that include the last 31 days.  Each model will be evaluated on how accurate they are in forecasting the test set's values.  I will use the RMSE as the metric to assess the accuracy.

```{r}
train_test_split <- function(atm_df, atm_number, n_in_test = 31, return_ts=TRUE){
  ### Splits the data into training and test sets
  # Args:
  #     atm_df (data.frame): The ATM data
  #     atm_number (int): Which ATM do you want the time series for?
  #     n_in_test (int): The number of observations in the test set taken from the end (optional-31 default)
  #     return_ts (logical): Should the function return ts objects (optional-TRUE default)
  # Returns:
  #     train_test_ts (list): Two ts objects (train and test).
  
  # Subset the data frame
  df <- atm_df %>%
    filter(ATM == paste0("ATM", atm_number)) %>%
    select(-ATM)
  
  # Split the data frame into training and test sets
  test <- tail(df, n_in_test)
  train <- head(df, -n_in_test)
  
  # Tranform into ts objects
  if(return_ts){
    train_start <- (min(train$DATE))
    train <- ts(train$Cash, start = decimal_date(as.Date(train_start)), frequency = 365)
    test_start <- (min(test$DATE))
    test <- ts(test$Cash, start = decimal_date(as.Date(test_start)), frequency = 365)
  }
  
  # Return the data to the user
  train_test <- list(train = train, test = test)
  return(train_test)
}

atm_1_ts <- train_test_split(adjusted_atm, 1, 31)
atm_2_ts <- train_test_split(adjusted_atm, 2, 31)
atm_3_ts <- train_test_split(adjusted_atm, 3, 31)
atm_4_ts <- train_test_split(adjusted_atm, 4, 31)

atm_1_df <- train_test_split(adjusted_atm, 1, 31, return_ts = FALSE)
atm_2_df <- train_test_split(adjusted_atm, 2, 31, return_ts = FALSE)
atm_3_df <- train_test_split(adjusted_atm, 3, 31, return_ts = FALSE)
atm_4_df <- train_test_split(adjusted_atm, 4, 31, return_ts = FALSE)
```

### ATM 1 Models

I will start by looking at the training data and the decomposition.  I cannot use the `decompose()` or `stl()` functions to decompose it because I don't have enough data.  Facebook Prophet can decompose it using its Bayesian estimation process.

```{r}
atm_prophet <- function(df, forcast_window){
  m <- df %>%
    mutate(y = Cash, ds = as.character(DATE)) %>%
    prophet()
  future <- make_future_dataframe(m, periods = forcast_window)
  atm_forecast <- predict(m, future)
  results = list(
    model = m,
    future = future,
    forecast = atm_forecast
  )
  return(results)
}

atm_1_prophet <- atm_prophet(atm_1_df$train, 31)
prophet_plot_components(atm_1_prophet$model, atm_1_prophet$forecast)
```

That is interesting! There appears to be a weekly effect in the data.  Wednesdays and especially Thursdays are low traffic days.  The trend apears to be decreasing but at a very slow rate.

```{r}
plot(atm_1_prophet$model, atm_1_prophet$forecast)
```

```{r}
atm_1_prophet$forecast %>%
  select(ds, yhat)
```
