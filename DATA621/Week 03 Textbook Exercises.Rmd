---
title: "DATA 621 Week #3 Textbook Exercises"
author: "Mike Silva"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: kate
    code_folding: "hide"
---


```{r knitr_init, echo=FALSE, cache=FALSE, warning=FALSE, message=FALSE}
library(knitr)
library(rmdformats)
library(tidyverse)
library(kableExtra)
library(gridExtra)
library(ggthemes)
## Global options
options(max.print="75")
opts_chunk$set(echo=TRUE,
	             cache=FALSE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE)
opts_knit$set(width=75)

# A Prefix nulling hook.

# Make sure to keep the default for normal processing.
default_output_hook <- knitr::knit_hooks$get("output")

# Output hooks handle normal R console output.
knitr::knit_hooks$set( output = function(x, options) {

  comment <- knitr::opts_current$get("comment")
  if( is.na(comment) ) comment <- ""
  can_null <- grepl( paste0( comment, "\\s*\\[\\d?\\]" ),
                     x, perl = TRUE)
  do_null <- isTRUE( knitr::opts_current$get("null_prefix") )
  if( can_null && do_null ) {
    # By default R print output aligns at the right brace.
    align_index <- regexpr( "\\]", x )[1] - 1
    # Two cases: start or newline
    re <- paste0( "^.{", align_index, "}\\]")
    rep <- comment
    x <- gsub( re, rep,  x )
    re <- paste0( "\\\n.{", align_index, "}\\]")
    rep <- paste0( "\n", comment )
    x <- gsub( re, rep,  x )
  }

  default_output_hook( x, options )

})

knitr::opts_template$set("kill_prefix"=list(comment=NA, null_prefix=TRUE))
```

## MARR 2.3

The manager of the purchasing department of a large company would like to develop a regression model to predict the average amount of times it takes to process a given number of invoices.  Over a 30-day period, data are collected on the number of invoices processed and the total time taken (in hours). The data are avialable in the file inovices.txt. The following modle was fit to the data $Y = \beta_0 + \beta_1 x + e$ where $Y$ is the processing time and $x$ is the number of invoices.  Utilizing the output of the fit of theis model provided below, complete the following tasks.

```{r comment=NA}
invoices <- read.delim('./data/invoices.txt')
fit <- lm(Time ~ Invoices, invoices)
summary(fit)
```

a) Find a 95% confidence interval for the start-up time, i.e., $\beta_0$. 

```{r}
confint(fit, "(Intercept)")
```

b) Suppose that a best practice benchmark for the average processing time for an additonal invoice is 0.01 hours (or 0.6 minutes).  Test the null hypothesis $H_0:\beta_1 = 0.01$ against a two-sided alternative.  Interpret your results.

```{r, null_prefix=TRUE}
# T statistic
abs(coef(summary(fit))[2, 1] - 0.01 / coef(summary(fit))[2, 2])
```

since the t is greater than  2.048 we reject the null hypothsis.  This suggests that the the observed invoice processing time is not equal to the best practice time.

c) Find a point estimate and a 95% prediction interval for the itme taken to process 130 invoices.

```{r, null_prefix=TRUE}
predict(fit, data.frame(Invoices = 130), interval="predict") 
```

## LMR 3.6

Thirty-nine MBA students were asked about hapiness and how it relates to their income and social life.  the data is found in `happy`.  Fit a regression model with `happy` as the response and the other four variables as predictors.

```{r, comment=NA}
happy <- read.delim('./data/happy.txt')
fit <- lm(happy ~ ., data = happy)
summary(fit)
```

a) What predictors were statistically significant at  the 1% level? **money**

b) Use the `table` function to produce a numerical summary of the response.  What assumption used to preform the t-tests seems questionable in light of this summary?  **Normally distributed residuals**

```{r, eval=FALSE}
table(happy$happy)
```

```{r}
happy %>%
  group_by(happy) %>%
  tally() %>%
  kable() %>%
  kable_styling()
```

c) Use the permutation process described in section 3.3 to test the significance of the `money` predictor.

```{r, null_prefix=TRUE}
nreps <- 4000
set.seed(123)
t_stats <- numeric(nreps)
p_values <- numeric(nreps)
for(i in 1:nreps){
  fit <- lm(sample(happy) ~ ., data = happy)
  t_stats[i] <- summary(fit)[["coefficients"]][2, "t value"]
  p_values[i] <- summary(fit)[["coefficients"]][2, "Pr(>|t|)"]
  
}

mean(p_values)
```

d) Plot a histogram of the permutation t-statistics.  Make sure you use the probability rather than the frequency version of the histogram.

```{r}
hist(t_stats, freq = FALSE)
```

e)  Overlay an appropriate t-densisty over the histogram.  Hint: Use `grid <- seq(-3, 3, length = 300)` to create a grid of values, then use the `dt` function to compute the t-density on this grid and the `lines` function to superimpose the result.  

```{r}
grid <- seq(-3, 3, length = 300)
hist(t_stats, freq = FALSE)
lines(grid, dt(grid, 34))
```

f) Use the bootstrap procedure from Section 3.6 to compute 90% and 95% confidence intervals for $\beta_\text{money}$.  Does zero fall within these confidence intervals?  Are the results consistent with previous tests?

```{r}
set.seed(123)
nb <- 4000
bootstrap_coefficients <- matrix(NA, nb, length(coef(fit)))
for (i in 1:nb){
  bfit <- lm(sample(happy) ~ ., data = happy)
  bootstrap_coefficients[i,] <- coef(bfit)
}

bootstrap_coefficients <- as.data.frame(bootstrap_coefficients)
names(bootstrap_coefficients) <- names(coef(bfit))
```

```{r}
# 95% CI
apply(bootstrap_coefficients, 2, function(x) quantile(x, c(0.025, 0.975)))
```

```{r}
# 90% CI
apply(bootstrap_coefficients, 2, function(x) quantile(x, c(0.05, 0.95)))
```

**Zero falls within the CI's.  This is consistent with the other results.**

## LMR 4.5

For the `fat` data used in this chapter, a smaller model using only `age`, and `weight`, `height` and `abdom` was proposed on the grounds that these predictors are either known by the individual or easily measured.

a. Compare this model to the full thirteen predictor model used earlier in the chapter.  Is it justifiable to use the smaller model?

```{r}
fat <- read.delim('./data/fat.txt') 
full <- lm(brozek ~ age + weight + height + neck + chest + abdom + hip + thigh + knee + ankle + biceps + forearm + wrist, data = fat)
small <- lm(brozek ~ age + weight + height + abdom, data = fat)
summary(small)
```

b. Compute a 95% prediction interval for median predictor values and compare to the results to the interval for the full model.  Do the intervals differ by a practically important amount? **No it doesn't differ.  See below:**

### Small Model

```{r}
x0 <- data.frame(t(apply(model.matrix(full), 2, median)))
predict(small, x0, interval = "prediction")
```

### Full Model

```{r}
predict(full, x0, interval = "prediction")
```

c. For the smaller model, examine all the observations from case number 25 to 50.  Which two observations are particularly anomalous? **Case 25 and 33.**

```{r}
data.frame(actual = fat[25:50, "brozek"], yhat = round(predict(small, fat)[25:50], 1)) %>% 
  rownames_to_column() %>%
  mutate(error = abs((yhat - actual)/yhat)) %>% 
  arrange(desc(error)) %>%
  top_n(5) %>%
  kable() %>% 
  kable_styling()
```

d. Recompute the 95% prediction interval for the median predictors after these two anomoulous cases have been excluded from the data.  Did this make much difference to the outcome? **It certainly did.  See below:**

```{r}
fat <- fat[!row.names(fat) %in% c(25,33),]

full <- lm(brozek ~ age + weight + height + neck + chest + abdom + hip + thigh + knee + ankle + biceps + forearm + wrist, data = fat)
small <- lm(brozek ~ age + weight + height + abdom, data = fat)

x0 <- data.frame(t(apply(model.matrix(full), 2, median)))
```

### Small Model

```{r}
predict(small, x0, interval = "prediction")
```

### Full Model

```{r}
predict(full, x0, interval = "prediction")
```


## LMR 5.2

Use the `odor` dataset with odor as the response variable and `temp` as the predictor. Consider all possible models that also include all, some or none of the other two predictors.  Report the coefficient for temperature, its standard error, t-statistic and p-value in each case. Discuss what stays the same, what changes and why.  Which model is the best?

```{r}
odor <- read.delim("data/odor.txt")
models <- c("odor ~ temp", "ordor ~ temp + gas", "ordor ~ temp + pack", "ordor ~ temp + gas + pack")
coefficients <- matrix(NA, 4, 6)

fit <- lm(odor ~ temp, data = odor)
coefficients[1,] <- c("odor ~ temp", summary(fit)$coefficients[2,], summary(fit)$adj.r.squared)
fit <- lm(odor ~ temp + gas, data = odor)
coefficients[2,] <- c("odor ~ temp + gas", summary(fit)$coefficients[2,], summary(fit)$adj.r.squared)
fit <- lm(odor ~ temp + pack, data = odor)
coefficients[3,] <- c("odor ~ temp + pack", summary(fit)$coefficients[2,], summary(fit)$adj.r.squared)
fit <- lm(odor ~ temp + gas + pack, data = odor)
coefficients[4,] <- c("odor ~ temp + gas + pack", summary(fit)$coefficients[2,], summary(fit)$adj.r.squared)
coefficients <- as.data.frame(coefficients)
names(coefficients) <- c("Formula", names(summary(fit)$coefficients[2,]), "Adjusted R-squared")
coefficients %>%
  kable() %>%
  kable_styling()
```


## LMR 14.2