{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T22:24:13.679079Z",
     "start_time": "2020-10-08T22:24:11.421761Z"
    }
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "paths = [\"./iNaturalist/images/Poison Ivy\"]\n",
    "n_training_images_per_class = 500\n",
    "percent_test = .1\n",
    "\n",
    "# =========== You Shouldn't Have To Edit Beyond This Point ===========\n",
    "class_file_path = paths[0] + \"/classes.txt\"\n",
    "dataset_name = \"v5_\" + str(n_training_images_per_class)\n",
    "dataset_path = \"./dataset/\" + dataset_name\n",
    "total_training_images = 0\n",
    "total_test_images = 0\n",
    "\n",
    "\n",
    "def build_dataset(dataset_path, training_labels, testing_labels):\n",
    "    steps = {\"train\":training_labels, \"val\":testing_labels}\n",
    "    for path, label_paths in steps.items():\n",
    "        for label_path in label_paths:\n",
    "            record_id = label_path.split(\"\\\\\")[-1].split(\".txt\")[0]\n",
    "            p = label_path.split(record_id)[0]\n",
    "            img_path = glob(p + record_id + \".j*\")[0]\n",
    "            new_img_path = dataset_path + \"/images/\" + path + \"/\" + record_id + \".jpg\"\n",
    "            new_label_path = dataset_path + \"/labels/\" + path + \"/\" + record_id + \".txt\"\n",
    "            shutil.copyfile(img_path, new_img_path)\n",
    "            shutil.copyfile(label_path, new_label_path)\n",
    "            \n",
    "            \n",
    "def init_clean_dir(path):\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.mkdir(path)\n",
    "\n",
    "    \n",
    "def init_yolov5_dataset_directories(base_path):\n",
    "    init_clean_dir(base_path)\n",
    "    init_clean_dir(base_path + \"/images\")\n",
    "    init_clean_dir(base_path + \"/images/train\")\n",
    "    init_clean_dir(base_path + \"/images/val\")\n",
    "    init_clean_dir(base_path + \"/labels/\")\n",
    "    init_clean_dir(base_path + \"/labels/train\")\n",
    "    init_clean_dir(base_path + \"/labels/val\")\n",
    "\n",
    "\n",
    "def train_test_split(base_path, n_train, p_test):\n",
    "    n_test = int( n_train / (1 - p_test)) - n_train\n",
    "    total_images_needed = n_train + n_test\n",
    "    labels = glob(base_path + \"/*.txt\")\n",
    "    labels.remove(base_path + \"\\\\classes.txt\")\n",
    "    if len(labels) < total_images_needed:\n",
    "        print(\"Not Enough Labeled Images\")\n",
    "    else:\n",
    "        for_training = random.sample(labels, n_train)\n",
    "        for_testing = np.setdiff1d(labels, for_training)\n",
    "        for_testing = random.sample(for_testing.tolist(), n_test)\n",
    "        return (for_training, for_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the custom data set for YOLOv5 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T22:24:56.792207Z",
     "start_time": "2020-10-08T22:24:13.679079Z"
    }
   },
   "outputs": [],
   "source": [
    "init_yolov5_dataset_directories(dataset_path)  \n",
    "\n",
    "for path in paths:\n",
    "    train, test = train_test_split(path, n_training_images_per_class, percent_test)\n",
    "    build_dataset(dataset_path, train, test)\n",
    "    total_training_images += len(train)\n",
    "    total_test_images += len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Config YAML\n",
    "Generate the YAML used to train the YOLOv5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T22:24:56.807036Z",
     "start_time": "2020-10-08T22:24:56.792207Z"
    }
   },
   "outputs": [],
   "source": [
    "names = \"names: [\"\n",
    "n_classes = 0\n",
    "file = open(class_file_path, \"r\")\n",
    "for line in file.readlines():\n",
    "    n_classes += 1\n",
    "    names += \"'\" + line.strip() + \"', \"\n",
    "names = names[:len(names)-2] + \"]\"\n",
    "\n",
    "f = open(dataset_path + \"/data.yaml\", \"w\")\n",
    "f.write(\"train: ../data/images/train/\\r\")\n",
    "f.write(\"val: ../data/images/val/\\r\")\n",
    "f.write(\"\\r\")\n",
    "f.write(\"nc: \" + str(n_classes) + \"\\r\")\n",
    "f.write(\"\\r\")\n",
    "f.write(names)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLOv5 YAML\n",
    "Generate the YOLOv5 config YAML by taking the base YAML and editing the number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T22:24:57.166579Z",
     "start_time": "2020-10-08T22:24:56.808034Z"
    }
   },
   "outputs": [],
   "source": [
    "file = open(\"yolov5x.yaml\", \"r\")\n",
    "lines = file.readlines()\n",
    "lines[1] = \"nc: \"+str(n_classes)+\"  # number of classes\\n\"\n",
    "f = open(dataset_path + \"/yolov5x.yaml\", \"w\")\n",
    "f.writelines([\"%s\" % line  for line in lines])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create README\n",
    "Add in some details into a README file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T22:24:57.213071Z",
     "start_time": "2020-10-08T22:24:57.167594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 images in training set\n"
     ]
    }
   ],
   "source": [
    "msg = str(total_training_images) + \" images in training set\"\n",
    "f = open(dataset_path + \"/README\", \"w\")\n",
    "f.write(msg)\n",
    "f.write(\"\\r\")\n",
    "f.close()\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T22:24:57.337317Z",
     "start_time": "2020-10-08T22:24:57.214038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 images in test set\n"
     ]
    }
   ],
   "source": [
    "msg = str(total_test_images) + \" images in test set\"\n",
    "f = open(dataset_path + \"/README\", \"a\")\n",
    "f.write(msg)\n",
    "f.write(\"\\r\")\n",
    "f.close()\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T22:24:57.368403Z",
     "start_time": "2020-10-08T22:24:57.338976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 classes in total\n"
     ]
    }
   ],
   "source": [
    "msg = str(n_classes) + \" classes in total\"\n",
    "f = open(dataset_path + \"/README\", \"a\")\n",
    "f.write(msg)\n",
    "f.close()\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zip it up\n",
    "\n",
    "Finally compress everything so it can be uploaded to the cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T22:25:05.402697Z",
     "start_time": "2020-10-08T22:24:57.371400Z"
    }
   },
   "outputs": [],
   "source": [
    "shutil.make_archive(\"./dataset/\" + dataset_name, \"zip\", dataset_path)\n",
    "shutil.rmtree(dataset_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
